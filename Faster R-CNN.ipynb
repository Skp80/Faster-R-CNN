{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "Faster R-CNN.ipynb",
      "provenance": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0Dn0SmWkikx",
        "colab_type": "text"
      },
      "source": [
        "# Faster R-CNN Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nvVCrlJX5XD_",
        "colab_type": "text"
      },
      "source": [
        "##Toolbox"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KrPJBdPBZ-x_",
        "colab_type": "code",
        "outputId": "87e64754-5cca-4807-c985-4366fa6d0e4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dteJlA58p3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import doctest\n",
        "import os\n",
        "import random\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
        "from tensorflow.keras.layers import Flatten, Dense, Input, Conv2D, MaxPooling2D, Dropout, Layer, Concatenate\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, TimeDistributed\n",
        "\n",
        "seed = 1111"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8VFTrKjIdH56",
        "colab_type": "code",
        "outputId": "155b365c-ce91-4046-8298-569ace710378",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "doctest.testmod(verbose=True)\n",
        "def iou(bbox1, bbox2):\n",
        "  '''\n",
        "  Bbox format must be [x_min,y_min,x_max,y_max]\n",
        "  >>> iou([10,10,10,10],[5,5,5,5])\n",
        "  0\n",
        "  >>> iou([0,0,4,4],[2,2,4,4])\n",
        "  0.25\n",
        "  >>> iou([0,0,4,4],[2,2,6,6])\n",
        "  0.14285714285714285\n",
        "  '''\n",
        "\n",
        "  xmin_inter = max(bbox1[0],bbox2[0])\n",
        "  ymin_inter = max(bbox1[1],bbox2[1])\n",
        "  xmax_inter = min(bbox1[2],bbox2[2])\n",
        "  ymax_inter = min(bbox1[3],bbox2[3])\n",
        "\n",
        "  width_inter = max(xmax_inter - xmin_inter,0)\n",
        "  height_inter = max(ymax_inter - ymin_inter,0)\n",
        "  if(width_inter == 0 or height_inter == 0):\n",
        "    iou = 0\n",
        "  else:\n",
        "    iou = width_inter*height_inter/((bbox1[2]-bbox1[0])*((bbox1[3]-bbox1[1]))+(bbox2[2]-bbox2[0])*((bbox2[3]-bbox2[1]))-width_inter*height_inter)\n",
        "  return iou\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 items had no tests:\n",
            "    __main__\n",
            "0 tests in 1 items.\n",
            "0 passed and 0 failed.\n",
            "Test passed.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5qMZAWnd678",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculate_delta(bbox1,bbox2):\n",
        "  '''\n",
        "  Bbox format must be [x_min,y_min,x_max,y_max]\n",
        "  return the delta between ground bbox (bbox1) and anchors(bbox2)\n",
        "  '''\n",
        "  xmin_d = bbox1[0] - bbox2[0]\n",
        "  ymin_d = bbox1[1] - bbox2[1]\n",
        "  xmax_d = bbox1[2] - bbox2[2]\n",
        "  ymax_d = bbox1[3] - bbox2[3]\n",
        "  return xmin_d,ymin_d,xmax_d,ymax_d"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvgFWgVm2FwM",
        "colab_type": "text"
      },
      "source": [
        "##Architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kv9MqH-v2Io3",
        "colab_type": "text"
      },
      "source": [
        "##Input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MG_Ps_0tKL3V",
        "colab_type": "code",
        "outputId": "a13859c0-f383-4731-cd51-0f3e56b8e8e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n",
            "/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yp4lVor3KHMs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_filepath = 'My Drive/SoccerAI/train_resources'\n",
        "# Input file for training is train_annotation.txt\n",
        "train_filepath = base_filepath+'/train_annotation.txt'\n",
        "train_df = pd.read_csv(train_filepath,header=None,names=['ID','Filepath','XMin','YMin','XMax','YMax','Class'])\n",
        "train_df = train_df.set_index('ID')\n",
        "train_imgs = train_df.index.unique()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJ5_xFTFYRCn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = train_df['Class'].unique()\n",
        "\n",
        "def class_dict(labels):\n",
        "  '''\n",
        "  Create a dictionnary from the list of available classes\n",
        "  Output : {1:Class1, ....n:Classn, n+1:Background}\n",
        "  '''\n",
        "  class_dict = {}\n",
        "  j = 0\n",
        "  for label in labels:\n",
        "    class_dict.update({j:label})\n",
        "    j+=1\n",
        "  class_dict.update({j:'bg'})\n",
        "  revert_class_dict = {}\n",
        "  for k,v in class_dict.items():\n",
        "    revert_class_dict.update({v:k})\n",
        "  return class_dict,revert_class_dict\n",
        "labels_dict,labels_revert_dict = class_dict(classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMyoeumtZ4Cb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def input_train_gen(df,labels_revert_dict):\n",
        "  img_ids = df['ID'].unique()\n",
        "  for img_id in img_ids:\n",
        "    bboxes = []\n",
        "    sub_df = df[df['ID']=img_id]\n",
        "    for index,row in sub_df:\n",
        "      class_id = labels_revert_dict.get(row['Class'])\n",
        "      xmin = row['XMin']\n",
        "      ymin = row['YMin']\n",
        "      xmax = row['XMax']\n",
        "      ymax = row['YMax']\n",
        "      bboxes.append([xmin,ymin,xmax,ymax,class_id])\n",
        "    yield bboxes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tJYpnsh-XYu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_height = 600\n",
        "img_width = 800\n",
        "img_depth = 3\n",
        "input_shape = (img_height,img_width,img_depth)\n",
        "\n",
        "def input_tensor(input_shape):\n",
        "  x = Input(shape = input_shape)\n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWgsGzoj2MaQ",
        "colab_type": "text"
      },
      "source": [
        "## Base Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5vLawviCqOi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vgg_ratio = 16"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9LpXzRi07eRq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def vgg16(input_tensor):\n",
        "      \n",
        "    # Block 1\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1')(input_tensor)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
        "\n",
        "    # Block 2\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1')(x)\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
        "\n",
        "    # Block 3\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1')(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2')(x)\n",
        "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
        "\n",
        "    # Block 4\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3')(x)\n",
        "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
        "\n",
        "    # Block 5\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2')(x)\n",
        "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3')(x)\n",
        "\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DI2Lo-v3_6Cj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_weights(weights):\n",
        "  return None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-S5Uilc2Pho",
        "colab_type": "text"
      },
      "source": [
        "##RPN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wdt1NYkWAAQi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rpn_height = img_height/vgg_ratio\n",
        "rpn_width = img_width/vgg_ratio\n",
        "rpn_depth = 512\n",
        "anchors_ratios = [0.5,1,1.5]\n",
        "anchors_size = [64,128,256]\n",
        "anchors_count = len(anchors_ratios) * len(anchors_size)\n",
        "\n",
        "\n",
        "def rpn(x):\n",
        "  \n",
        "  # Mutual Layer\n",
        "  x1 = Conv2D(512,(3,3), activation='relu', padding='same', kernel_initializer='normal', name='rpn_mutual_layer')(x)\n",
        "  \n",
        "  # Classification Layer\n",
        "  x_class = Conv2D(anchors_count, (1,1), activation = 'sigmoid', kernel_initializer = 'uniform', name='rpn_class_layer')(x)\n",
        "  \n",
        "  # Regression Layer\n",
        "  x_reg = Conv2D(4*anchors_count, (1,1), activation='linear', kernel_initializer='zero', name='rpn_reg_layer')(x)\n",
        "  return [x_class,x_reg]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DszTJ_IyWunY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Anchors Rep shape is (rpn_height,rpn_width,len(anchors_ratio)*len(anchors),4) stands for xmin,ymin,xmax,ymax\n",
        "def anchors_list(vgg_ratio,rpn_height,rpn_width,anchors_ratios,anchors_size):\n",
        "  anchors = np.zeros((rpn_height,rpn_width,len(anchors_ratios)*len(anchors_size),4))\n",
        "  for i in range(0,rpn_height):\n",
        "    for j in range(0,rpn_width):\n",
        "      k = 0\n",
        "      for ratio in anchors_ratios:\n",
        "        for size in anchors_size:\n",
        "          xcenter = i*vgg_ratio + vgg_ratio/2\n",
        "          ycenter = j*vgg_ratio + vgg_ratio/2\n",
        "          anchors_width = ratio*size\n",
        "          anchors_height = size\n",
        "          xmin = xcenter - anchors_width/2\n",
        "          ymin = ycenter - anchors_height/2\n",
        "          xmax = xcenter + anchors_width/2\n",
        "          ymax = ycenter + anchors_height/2\n",
        "          anchors[i][j][k][0] = xmin\n",
        "          anchors[i][j][k][1] = ymin\n",
        "          anchors[i][j][k][2] = xmax\n",
        "          anchors[i][j][k][3] = ymax\n",
        "          k+=1\n",
        "  return anchors\n",
        "\n",
        "anchors = anchors_list(vgg_ratio,int(rpn_height),int(rpn_width),anchors_ratios,anchors_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCftEwbplbh9",
        "colab_type": "code",
        "outputId": "0c9a37bb-4248-45ea-b750-11098e52c82d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "bg_threshold = 0.1\n",
        "fg_threshold = 0.5\n",
        "batch_size = 256\n",
        "\n",
        "# Sampling the anchors to have balanced batch\n",
        "def create_sample_rpn(pos,neut,neg,batch_size):\n",
        "  '''\n",
        "  Create a balanced minibatch from positive anchors, Negative anchors and complete with neutral anchors if required\n",
        "  '''\n",
        "  half_batch = int(batch_size/2)\n",
        "  sample = []\n",
        "  num_pos = len(pos)\n",
        "  num_neg = len(neg)\n",
        "  random.shuffle(pos)\n",
        "  neut = sorted(neut, key=lambda x: x[1], reverse=True)\n",
        "  random.shuffle(pos)\n",
        "  if(num_pos >= half_batch):\n",
        "    pos = pos[:half_batch]\n",
        "  else:\n",
        "    neut_temp = [x[0] for x in neut[:(half_batch-num_pos)]]\n",
        "    pos = pos + neut_temp\n",
        "  if(num_neg >= half_batch):\n",
        "    neg = neg[:half_batch]\n",
        "  else:\n",
        "    neut_temp = [x[0] for x in neut[-(half_batch-num_neg):]]\n",
        "    neg = neg + neut_temp\n",
        "  assert len(pos) == int(batch_size/2)\n",
        "  assert len(neg) == int(batch_size/2)\n",
        "  return pos,neg\n",
        "\n",
        "def create_sample_cnn(pos,neut,neg,batch_size):\n",
        "  '''\n",
        "  Create a balanced minibatch from positive anchors, Negative anchors and complete with neutral anchors if required\n",
        "  '''\n",
        "  half_batch = int(batch_size/2)\n",
        "  sample = []\n",
        "  num_pos = len(pos)\n",
        "  num_neg = len(neg)\n",
        "  random.shuffle(pos)\n",
        "  neut = sorted(neut, key=lambda x: x[1], reverse=True)\n",
        "  random.shuffle(pos)\n",
        "  if(num_pos >= half_batch):\n",
        "    pos = pos[:half_batch]\n",
        "  else:\n",
        "    neut_temp = [x[0] for x in neut[:(half_batch-num_pos)]]\n",
        "    pos = pos + neut_temp\n",
        "  if(num_neg >= half_batch):\n",
        "    neg = neg[:half_batch]\n",
        "  else:\n",
        "    neut_temp = [x[0] for x in neut[-(half_batch-num_neg):]]\n",
        "    neg = neg + neut_temp\n",
        "  assert len(pos) == int(batch_size/2)\n",
        "  assert len(neg) == int(batch_size/2)\n",
        "  return pos,neg\n",
        "\n",
        "# Calculation of IoU for each anchors\n",
        "def anchors_iou(anchors,ground_truth_bboxes,bg_threshold,fg_threshold, batch_size_rpn,batch_size_cnn):\n",
        "  '''\n",
        "  anchors input parameter is the lsit of anchors returned by anchors_list()\n",
        "  ground_truth_bboxes is the list of ground truth bboxes for a giving image. Shape is (?,5) with 5 stands for xmin,ymin,xmax,ymax,class\n",
        "  Output1 : anchors_cls which shape is (?,rpn_width,rpn_height,num_anchors*2). \n",
        "  Last dim from 0 to num_anchors indicates whether the anchors is in the training batch. From num_anchors to 2*num_anchors indicates\n",
        "  the target value\n",
        "  Output2 : anchors_reg which shape is (?,rpn_width,rpn_height,num_anchors*4*2)\n",
        "\n",
        "  '''\n",
        "  assert fg_threshold > bg_threshold\n",
        "  neg = []\n",
        "  neut = []\n",
        "  pos = []\n",
        "  anchors_reg = np.zeros((len(anchors),len(anchors[0]),anchors_count*2*4))\n",
        "  anchors_cls = np.zeros((len(anchors),len(anchors[0]),anchors_count*2))\n",
        "  for i in range(0,len(anchors)):\n",
        "    for j in range(0,len(anchors[i])):\n",
        "      for k in range(0,len(anchors[i][j])):\n",
        "        iou_temp = 0\n",
        "        for bbox in ground_truth_bboxes:\n",
        "          if(iou_temp < iou(bbox,anchors[i][j][k])):\n",
        "            iou_temp = iou(bbox,anchors[i][j][k])\n",
        "            dxmin,dymin,dxmax,dymax = calculate_delta(bbox[:4],anchors[i][j][k])\n",
        "            anchors_reg[i][j][k+4*anchors_count] = dxmin\n",
        "            anchors_reg[i][j][k+1+4*anchors_count] = dymin\n",
        "            anchors_reg[i][j][k+2+4*anchors_count] = dxmax\n",
        "            anchors_reg[i][j][k+3+4*anchors_count] = dymax\n",
        "            class_id = bbox[4]\n",
        "        if(iou_temp > fg_threshold):\n",
        "          pos.append((i,j,k))\n",
        "        elif(iou_temp < bg_threshold):\n",
        "          neg.append((i,j,k))\n",
        "          class_id = labels_revert_dict.get('bg')\n",
        "        else:\n",
        "          neut.append([(i,j,k),iou_temp])\n",
        "          class_id = labels_revert_dict.get('bg')\n",
        "  pos_samples,neg_samples = create_sample_rpn(pos,neut,neg,batch_size_rpn)\n",
        "  \n",
        "  for indexes in pos_samples:\n",
        "    anchors_cls[indexes[0]][indexes[1]][indexes[2]]=1\n",
        "    anchors_cls[indexes[0]][indexes[1]][indexes[2] + anchors_count]=1\n",
        "    anchors_reg[indexes[0]][indexes[1]][indexes[2]]=1\n",
        "    anchors_reg[indexes[0]][indexes[1]][indexes[2] + 1]=1\n",
        "    anchors_reg[indexes[0]][indexes[1]][indexes[2] + 2]=1\n",
        "    anchors_reg[indexes[0]][indexes[1]][indexes[2] + 3]=1\n",
        "  for indexes in neg_samples:\n",
        "    anchors_cls[indexes[0]][indexes[1]][indexes[2]]=1\n",
        "    anchors_reg[indexes[0]][indexes[1]][indexes[2]]=1\n",
        "    anchors_reg[indexes[0]][indexes[1]][indexes[2] + 1]=1\n",
        "    anchors_reg[indexes[0]][indexes[1]][indexes[2] + 2]=1\n",
        "    anchors_reg[indexes[0]][indexes[1]][indexes[2] + 3]=1\n",
        "  return anchors_cls,anchors_reg\n",
        "\n",
        "anchors_cls,anchors_reg = anchors_iou(anchors,[[0.5*img_width,0.5*img_height,0.8*img_width,0.8*img_height]],bg_threshold,fg_threshold,batch_size)\n",
        "\n",
        "print(anchors_cls.shape)\n",
        "print(anchors_reg.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(37, 50, 18)\n",
            "(37, 50, 72)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U5dCV6PepByh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def rpn_binary_crossentropy(anchors_count):\n",
        "  '''\n",
        "  The shape of y_pred is (rpn_height,rpn_width,anchors_count)\n",
        "  The shape of y_true is (rpn_height,rpn_width,anchors_count*2) [:,:,:anchors_count] is validity tensor and [:,:,anchors_count:] is GT\n",
        "  '''\n",
        "  def rpn_binary_crossentropy_fixed_anchors(y_true,y_pred):\n",
        "\n",
        "    return 1 * K.sum(y_true[:,:,:anchors_count] * K.binary_crossentropy(y_true[:,:,anchors_count:]))/K.sum(y_true[:,:,:anchors_count])\n",
        "  return rpn_binary_crossentropy_fixed_anchors\n",
        "\n",
        "HUBER_DELTA = 0.5\n",
        "def rpn_smooth_l1(anchors_count):\n",
        "  '''\n",
        "  The shape of y_pred is (rpn_height,rpn_width,anchors_count*4)\n",
        "  The shape of y_true is (rpn_height,rpn_width,anchors_count*2*4) [:,:,:anchors_count*4] is validity tensor and [:,:,anchors_count*4:] is GT\n",
        "  '''\n",
        "  def rpn_smooth_l1_fixed_anchors(y_true,y_pred):\n",
        "\n",
        "    x   = K.abs(y_true[:,:,anchors_count*4:] - y_pred)\n",
        "    x   = K.switch(x < HUBER_DELTA, 0.5 * x ** 2, HUBER_DELTA * (x - 0.5 * HUBER_DELTA))\n",
        "    return K.sum(y_true[:,:,:anchors_count*4]*x)/K.sum(y_true[:,:,:anchors_count*4])\n",
        "  return rpn_smooth_l1_fixed_anchors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqZt2eDI2SKI",
        "colab_type": "text"
      },
      "source": [
        "##ROI"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wYEV9LbAZmFo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ROIPoolingLayer(Layer):\n",
        "    '''\n",
        "    Input will be : [VGG16 Feature Layers, Proposal]\n",
        "    Shape is [(1,rpn_width,rpn_height,512),(1,x,y,h,w)]\n",
        "    '''\n",
        "    def __init__(self, pooling_size, **kwargs):\n",
        "        \n",
        "        self.pooling_size = pooling_size\n",
        "        \n",
        "        super(ROIPoolingLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.nb_channels = input_shape[0][3]\n",
        "\n",
        "    def call(self, x):\n",
        "        assert len(x) == 2\n",
        "        img = x[0]\n",
        "        roi = x[1]\n",
        "        \n",
        "        x = roi[0,0]\n",
        "        y = roi[0,1]\n",
        "        h = roi[0,2]\n",
        "        w = roi[0,3]\n",
        "        \n",
        "        x = K.cast(x, 'int32')\n",
        "        y = K.cast(y, 'int32')\n",
        "        w = K.cast(w, 'int32')\n",
        "        h = K.cast(h, 'int32')\n",
        "\n",
        "\n",
        "        output = tf.image.resize(img[:, y:y+h, x:x+w, :], (self.pooling_size, self.pooling_size))\n",
        "        output = K.reshape(output , (1, self.pooling_size, self.pooling_size, self.nb_channels))\n",
        "        return output\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return None, self.pooling_size, self.pooling_size, self.nb_channels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlYNAItP2UUB",
        "colab_type": "text"
      },
      "source": [
        "##R-CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lpq0yxB9bYBh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes_count = 3\n",
        "def rcnn(x):\n",
        "  \n",
        "  # Flatten Layer\n",
        "  x = Flatten()(x)\n",
        "  \n",
        "  # 1st Dense Layer\n",
        "  x = Dense(4096,activation='relu',kernel_initializer='normal', name='rcnn_dense1' )(x)\n",
        "\n",
        "  # 2nd Dense Layer\n",
        "  x = Dense(4096,activation='relu',kernel_initializer='normal', name='rcnn_dense2')(x)\n",
        "  \n",
        "  # Classification Layer\n",
        "  x_class = Dense(classes_count+1, activation = 'softmax', kernel_initializer = 'uniform', name='rcnn_class_layer')(x)\n",
        "  \n",
        "  # Regression Layer\n",
        "  x_reg = Dense(4*classes_count, activation='linear', kernel_initializer='zero', name='rcnn_reg_layer')(x)\n",
        "  \n",
        "  return [x_class,x_reg]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGOIGk5SVXP-",
        "colab_type": "text"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpWMOonQVZIr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base_weight_filepath = 'My Drive/SoccerAI/model/vgg16_weights.h5'\n",
        "trained_weight_filepath = 'My Drive/SoccerAI/model/model_frcnn.hdf5'\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AybLohh1c4U4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_test = input_tensor(input_shape)\n",
        "vgg16_model = vgg16(input_test)\n",
        "output = rpn(vgg16_model)\n",
        "print(vgg16_model)\n",
        "print(output)\n",
        "output_test = K.reshape(output[1],(66600,4))\n",
        "#output_test = K.squeeze(output_test,axis=0)\n",
        "print(output_test)\n",
        "output = ROIPoolingLayer(7)([vgg16_model,output_test])\n",
        "print(output)\n",
        "output = rcnn(output)\n",
        "print(output)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}